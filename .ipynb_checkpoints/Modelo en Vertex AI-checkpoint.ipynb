{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bcf1b2",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e366e2",
   "metadata": {},
   "source": [
    "Declarar constantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614de332",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0] # Nombre del proyecto\n",
    "\n",
    "REGION = 'us-central1' # Ubicación servidores a usar\n",
    "EXPERIMENT = '05'\n",
    "SERIES = '05'\n",
    "\n",
    "# Parámetros BigQuery\n",
    "BQ_PROJECT = PROJECT_ID # Proyecto de BigQuery\n",
    "BQ_DATASET = 'fraud' # Nombre del dataset dentro de BigQuery\n",
    "BQ_TABLE = 'fraud_prepped' # Nombre de tabla dentro del dataset\n",
    "\n",
    "# Recuersos\n",
    "DEPLOY_COMPUTE = 'n1-standard-4' # Tipo de hardware\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest' # Imagen de Docker a usar\n",
    "\n",
    "# Parámetros para entrenamiento de modelo\n",
    "VAR_TARGET = 'Class' # Nombre (field) de las etiquetas en la tabla\n",
    "VAR_OMIT = 'transaction_id' # Variables a omitir\n",
    "EPOCHS = 4 # Épocas de entrenamiento\n",
    "BATCH_SIZE = 100 # Batch size de entrenamiento\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\") # Timestamp para usar como identificador\n",
    "BUCKET = PROJECT_ID # Bucket en Google Storage\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\" # URI en Google Storage\n",
    "DIR = f\"temp/{EXPERIMENT}\" # Path de carpeta temporal auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be9395-f783-4f2b-8354-8a38740514b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.10.0 tensorflow-io==0.27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f2936",
   "metadata": {},
   "source": [
    "Importaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d3707",
   "metadata": {},
   "source": [
    "Declarar clientes de BigQuery y de Google Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project = PROJECT_ID, location = REGION)\n",
    "bq = bigquery.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43acbc",
   "metadata": {},
   "source": [
    "Crear carpeta temporal auxiliar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf48dc3-cdbd-4e34-be4d-33c7563dbd33",
   "metadata": {},
   "source": [
    "## Datos de entrenamiento\n",
    "\n",
    "Se usan los datos de transacciones bancarias importados en tabla en BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93fde9",
   "metadata": {},
   "source": [
    "### Esquema de la tabla\n",
    "\n",
    "Recuperar información de las columnas de la tabla de datos.   \n",
    "En BigQuery se puede usar `INFORMATION_SCHEMA` para obtener información sobre las columnas de una tabla, como el nombre y el tipo de dato que contiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edde19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '{BQ_TABLE}'\"\n",
    "schema = bq.query(query).to_dataframe()\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968eba8",
   "metadata": {},
   "source": [
    "### Número de clases\n",
    "Obtener el número de clases distintas en el dataset programáticamente.    \n",
    "Sabemos que son dos (fraudulenta o normal), pero código puede ser útil en otros dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = bq.query(query = f'SELECT DISTINCT {VAR_TARGET} FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE {VAR_TARGET} is not null').to_dataframe()\n",
    "nclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce90cf60",
   "metadata": {},
   "source": [
    "### Preparación de columnas para TensorFlow I/O\n",
    "\n",
    "Usar esquema de la tabla para preparar inputs para TensorFlow I/O:\n",
    "- Crear lista con nombre de columnas a usar (omitir las innecesarias)\n",
    "- Definir el tipo de datos de cada columna a partir de los *data type* entregados en el esquema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIT = VAR_OMIT.split() + ['splits'] # Lista de columnas a omitir\n",
    "\n",
    "selected_fields = schema[~schema.column_name.isin(OMIT)].column_name.tolist() # Lista de columnas a leer\n",
    "\n",
    "# Lista con data type de las columnas a leer\n",
    "output_types = [dtypes.float64 if x=='FLOAT64' else dtypes.int64 for x in schema[~schema.column_name.isin(OMIT)].data_type.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169327f",
   "metadata": {},
   "source": [
    "## Leer data de tabla de BigQuery con TensorFlow I/O "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ad3922-4ebe-4fc2-b08a-bc05019f3e57",
   "metadata": {},
   "source": [
    "### Separar inputs en features y etiqueta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7456f0",
   "metadata": {},
   "source": [
    "Crear función que separa datos entre features y etiqueta.   \n",
    "Codifica en One-Hot las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95911ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transTable(row_dict):\n",
    "    target = row_dict.pop(VAR_TARGET)\n",
    "    target = tf.one_hot(tf.cast(target,tf.int64), nclasses)\n",
    "    target = tf.cast(target, tf.float32)\n",
    "    return(row_dict, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73388e33",
   "metadata": {},
   "source": [
    "### Función para leer batches con Tensorflow I/O\n",
    "\n",
    "Función que lee batches de datos desde la tabla de BigQuery usando Tensorflow I/O.   \n",
    "Se configura para leer data en paralelo para acelerar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_reader(split):\n",
    "    reader = BigQueryClient()\n",
    "\n",
    "    training = reader.read_session(\n",
    "        parent = f\"projects/{PROJECT_ID}\",\n",
    "        project_id = BQ_PROJECT,\n",
    "        table_id = BQ_TABLE,\n",
    "        dataset_id = BQ_DATASET,\n",
    "        selected_fields = selected_fields,\n",
    "        output_types = output_types,\n",
    "        row_restriction = f\"splits='{split}'\",\n",
    "        requested_streams = 3\n",
    "    )\n",
    "    \n",
    "    return training.parallel_read_rows(sloppy = True, num_parallel_calls = tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9d82a",
   "metadata": {},
   "source": [
    "Usar función para conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02718964",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bq_reader('TRAIN').prefetch(1).map(transTable).shuffle(BATCH_SIZE*10).batch(BATCH_SIZE)\n",
    "validate = bq_reader('VALIDATE').prefetch(1).map(transTable).batch(BATCH_SIZE)\n",
    "test = bq_reader('TEST').prefetch(1).map(transTable).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc84d95",
   "metadata": {},
   "source": [
    "### Revisar un batch de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, target in train.take(1):\n",
    "    print('features:\\n',list(features.keys()))\n",
    "    print('\\netiqueta:\\n',target[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359ac9a",
   "metadata": {},
   "source": [
    "## Definir modelo\n",
    "\n",
    "Se crea modelo de regresión logística:\n",
    "\n",
    "- Se definen los inputs del modelo.\n",
    "- Se usa Batch Normalization para normalizar datos.\n",
    "- Se construye modelo de regresión logistica con función de activación *softmax*.\n",
    "- Se compila el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d3792d-c1ed-4a1b-9a39-f9d7ab1e00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de regresion logística\n",
    "\n",
    "# Definición de input de modelo\n",
    "feature_columns = {header: tf.feature_column.numeric_column(header) for header in selected_fields if header != VAR_TARGET}\n",
    "feature_layer_inputs = {header: tf.keras.layers.Input(shape = (1,), name = header) for header in selected_fields if header != VAR_TARGET}\n",
    "\n",
    "# Concatenar columnas individuales de features en capa única\n",
    "feature_layer_outputs = tf.keras.layers.DenseFeatures(feature_columns.values(), name = 'feature_layer')(feature_layer_inputs)\n",
    "\n",
    "# Paso de Batch normalization\n",
    "normalized = tf.keras.layers.BatchNormalization(name = 'batch_normalization_layer')(feature_layer_outputs)\n",
    "\n",
    "# Capa fully connected con activación softmax\n",
    "logistic = tf.keras.layers.Dense(nclasses, activation = tf.nn.softmax, name = 'logistic')(normalized)\n",
    "\n",
    "# Construcción de modelo\n",
    "model = tf.keras.Model(\n",
    "    inputs = feature_layer_inputs,\n",
    "    outputs = logistic,\n",
    "    name = EXPERIMENT\n",
    ")\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.SGD(), #SGD or Adam\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = ['accuracy', tf.keras.metrics.AUC(curve = 'PR', name = 'auprc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063ec71-6bdb-4660-8c36-e9a1ac4c294e",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e7136",
   "metadata": {},
   "source": [
    "- Entrenar modelo con método *fit*.\n",
    "- Notar que se entrena en maquina local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68eeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar logs de TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = os.path.join(DIR, \"logs\", f'{TIMESTAMP}'), histogram_freq=1)\n",
    "# Entrenar modelo\n",
    "history = model.fit(train, epochs = EPOCHS, callbacks = [tensorboard_callback], validation_data = validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b5ded-680b-4537-b2ea-35712ce992b5",
   "metadata": {},
   "source": [
    "## Evaluar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc016d",
   "metadata": {},
   "source": [
    "Evaluar poder de generalización del modelo usando los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, auprc = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180dd37-ac7c-4d0f-8095-81793aa53009",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)\n",
    "\n",
    "actuals = np.empty(shape = [0, predictions.shape[1]])\n",
    "for features, target in test.take(-1): # -1 indicates all batches\n",
    "    actuals = np.append(actuals, target.numpy(), axis = 0)\n",
    "\n",
    "predictions_proba = np.max(predictions, axis = 1)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "actuals = np.argmax(actuals, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90393bcd-ce91-41fb-be30-4618f469be36",
   "metadata": {},
   "source": [
    "### Calcular métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221ab09-d759-4d21-8620-a5d4486f24e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.log_loss(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea81c35-23b9-4ff1-8bb9-988381f99260",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd05d09-5cc2-4671-b485-c1ea55aa11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.average_precision_score(actuals, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc6b44-77b5-4acb-813b-ff332a907985",
   "metadata": {},
   "source": [
    "## Visualizar curvas de entrenamiento y validación (Tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd476f-ca49-442f-8524-b762a6b21714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c6c6a-4b5e-44b4-aec0-64b449e36feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir $DIR/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913711d",
   "metadata": {},
   "source": [
    "## Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f63da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{URI}/models/{TIMESTAMP}/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc74a2d-53a3-4bc5-9042-032b9a3d3076",
   "metadata": {},
   "source": [
    "## Implementación de modelo (API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10036d46",
   "metadata": {},
   "source": [
    "### Registrar modelo en Vertex AI\n",
    "\n",
    "Verificar que modelo no haya sido agregado anteriormente.   \n",
    "Agregar modelo a Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Modelo ya existe\")\n",
    "    upload_model = False\n",
    "else:\n",
    "    print('Agregando modelo al registro')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = DEPLOY_IMAGE,\n",
    "        artifact_uri = f\"{URI}/models/{TIMESTAMP}/model\",\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd12b79",
   "metadata": {},
   "source": [
    "### Crear endpoint para hacer peticiones de predicciones\n",
    "\n",
    "Verificar si *endpoint* ya existe.   \n",
    "Crear *endpoint* (vacio por el momento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc28d98-b525-4385-9b95-489bf574f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a538bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d06eba-82dc-4d50-8405-800d756e3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_models = endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e49dd0",
   "metadata": {},
   "source": [
    "### Desplegar modelo a endpoint\n",
    "Agregar modelo en registro de Vertex AI al *endpoint* creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.deploy(\n",
    "    model = model,\n",
    "    deployed_model_display_name = model.display_name,\n",
    "    traffic_percentage = 100,\n",
    "    machine_type = DEPLOY_COMPUTE,\n",
    "    min_replica_count = 1,\n",
    "    max_replica_count = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58790ad",
   "metadata": {},
   "source": [
    "## Predicciones en línea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a01eb",
   "metadata": {},
   "source": [
    "### Extraer datos para hacer predicciones\n",
    "\n",
    "Se extraen 10 datos de *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68911df0-5bee-44fb-9bb8-5aa363ae1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pred = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({VAR_TARGET}, {VAR_OMIT}, splits)\n",
    "        FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\n",
    "        WHERE splits='TEST'\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d5eff9",
   "metadata": {},
   "source": [
    "### Obtener predicciones usando un cliente en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec05c59-dc93-4a69-90bf-5f3f96f4d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances = newobs[0:1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(instances = newobs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a8676",
   "metadata": {},
   "source": [
    "### Obtener predicciones con petición REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": newobs[0:1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362dd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd7c47",
   "metadata": {},
   "source": [
    "### Obtener predicciones con gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e56e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-12:m110"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
